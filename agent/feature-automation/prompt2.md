Objective: Create a script that runs the full pipeline from downloading contests from s3 to creating a file 'output/{timestamp}/DKEntries.csv' with lineups filled. Put it in 'scripts/run_full_pipeline.py'.

Pipeline steps:
1. Check that 'data/DKEntries.csv' and 'data/NFL_*.csv' are present. The * is a wildcard; there just needs to be a file that starts with 'NFL_' and ends with '.csv'; that is our sabersim projections file.
2. Run 'scripts/get_contests.py', which creats a file 'DKEntriesClassified.csv'. That file contains my contest entries along with the size classification for each contest under 'field_size_classification'. Extract each distinct field_size_classification; we will use this for our optimization runs.
3. From here, we need to set up our optimization runs for each field size classification. 'src/contests.yaml' contains the runs that need to be done for each field size. Only perform the runs for the field size classifications present in DKEntriesClassified.csv, and only do each field size's run one time. The runs for each field size need to be bundled exactly like they are in run_bundle_multiple.sh. Don't actually run the bash script; rather, transfer the exact logic into Python in this full pipeline script. Name the bundle Excel files according to the field size name, e.g. 'small.xlsx', 'extra_large.xlsx', etc.
4. Now we need to run the diversification in feature_diversify on the files output from the previous step. For this we will need the number of entries we have for each field size. Extract this from 'data/DKEntriesClassified.csv' along with each contest ID, which we will use in the next step. As an example, assume we have 2 'small' entries, 3 'medium', and 3 'large'. We run the diversification to pick 2 lineups from 'small.xlsx', 3 from 'medium.xlsx', and 3 from 'large.xlsx'. These files will be in the output folder from the run we just did. Ouptut the diversified lineups into 'output/{timestamp}/diversified.xlsx just like we do currently.
5. Now for the final step, creating the output DKEntries.csv. We have the contest size for each contest ID from the previous step. Assign each of the diversified lineups (from the just created diversified.xlsx) to an appropriately sized contest. Then, read 'data/DKEntries.csv' into a dataframe. Insert the new lineups into DKEntries dataframe, then write it to 'output/{timestamp}/DKEntries.csv'. Important note: the lineups should be in the format '{player name} ({player id})' so that we can upload them to Draftkings.